<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Play Audio Backwards</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>

<body class="bg-gray-100 flex flex-col gap-4 items-center justify-center h-screen w-screen">
  <div class="gap-1 text-xl grid grid-cols-2 grid-rows-2">
    <button id="startButton" class="bg-blue-500 text-white px-4 py-3 rounded-lg shadow">Start Recording</button>
    <button id="stopButton"  class="bg-red-500 text-white px-4 py-3 rounded-lg shadow">End Recording</button>
    <button id="playButton"  class="bg-green-500 text-white px-4 py-3 rounded-lg shadow">Play audio</button>
    <button id="backwardsButton" class="bg-yellow-500 text-white px-4 py-3 rounded-lg shadow">Play backwards</button>
  </div>
  <!-- <audio id="audio1" controls src=""></audio> -->

  <div class="flex flex-col gap-2 grow">
    <canvas id="waveform" class="bg-white"></canvas>
  </div>
  <!-- audio -->
  <script>
    function get(name) {
      return document.getElementById(name);
    }

    function sleep(ms) {
      return new Promise(resolve => setTimeout(resolve, ms));
    }

    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let mediaStream = null; // needs to be initialized in user event, eg. click
    let mediaRecorder = null;
    let audioChunks = []; // pieces of audio file data
    let audioBuffer = null;
    let reversedBuffer = null;
    let audioFormat = null;
    
    get('startButton').addEventListener('click', async () => {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(mediaStream);
      audioChunks = [];
      mediaRecorder.ondataavailable = (e) => {
        console.log('Data available');
        audioChunks.push(e.data);
        console.log('Audio file format:', e.data.type);
        audioFormat = e.data.type;
      }

      mediaRecorder.onstop = async () => {
        console.log('Recording stopped');

        console.log(audioChunks);
        
        // concat audio file data
        const blob = new Blob(audioChunks, { type: audioFormat });
        // turn blob into array buffer
        const arrayBuffer = await blob.arrayBuffer();
        // decode the result audio file, into array of sample points
        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        visualizeAudio(Array.from(audioBuffer.getChannelData(0)));

        // get('audio1').src = URL.createObjectURL(blob);
        // console.log(get('audio1').src);

        await sleep(1);

        // reverse the audio
        reversedBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
          const data = audioBuffer.getChannelData(channel);
          const reversedData = reversedBuffer.getChannelData(channel);
          for (let i = 0; i < audioBuffer.length; i++) {
            reversedData[i] = data[audioBuffer.length - i - 1];
          }
        }

      };
      mediaRecorder.start();
      console.log('Recording started');
    });

    get('stopButton').addEventListener('click', () => {
      if (! mediaRecorder) {
        return
      }
      mediaRecorder.stop(); // will trigger `mediaRecorder.ondatavailable`
      mediaStream.getTracks().forEach(track => track.stop());
    });

    get('playButton').addEventListener('click', () => {
      console.log('Playing audio');
      // get('audio1').play();
      // play audioBuffer instead
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      source.start();
    });

    get('backwardsButton').addEventListener('click', async () => {
      if (! reversedBuffer) {
        console.log('No reversed buffer');
        return;
      }
      const source = audioContext.createBufferSource();
      source.buffer = reversedBuffer;
      source.connect(audioContext.destination);
      source.start();
      console.log('Playing reversed audio');
    });

    function getCanvas(name) {
      const canvas = get(name);
      const context = canvas.getContext('2d');

      let width = window.innerWidth / 5 * 4;
      let height = window.innerHeight - 250;
      width = Math.floor(width);
      height = Math.floor(height);
      console.log(width, height, window.devicePixelRatio);
      // high DPI canvas
      canvas.width = width * window.devicePixelRatio;
      canvas.height = height * window.devicePixelRatio;
      canvas.style.width = `${width}px`;
      canvas.style.height = `${height}px`;
      
      context.strokeStyle = 'black';
      context.beginPath();
      context.moveTo(0, 0);
      context.lineTo(canvas.width, canvas.height);
      context.stroke();

      return [canvas, context];
    }

    const [canvas1, ctx1] = getCanvas('waveform');

    function visualizeAudio(data) {
      // data has much more elements than canvas1.width
      // so we need to divide the data into chunks, each with length of step
      let step = Math.ceil(data.length / canvas1.width);
      if (step == 0) {
        step = 1;
      }
      // we cannot use Math.max(...arr) because we would get stack overflow
      let dataMax = data.map(x => Math.abs(x)).reduce((a, b) => Math.max(a, b));
      // let h = canvas1.height / 2;
      function scale(y) {
        y /= dataMax; // y in [-1, 1]
        y = (1 - y) / 2 
        y *= canvas1.height;
        y = Math.floor(y);
        return y;
      }

      // console.log('Data length:', data.length);
      // console.log('Canvas width:', canvas1.width);
      // console.log('Step:', step);
      // console.log('Max:', max);
      window.ctx1 = ctx1;
      
      ctx1.fillStyle = 'white';
      ctx1.fillRect(0, 0, canvas1.width, canvas1.height);

      ctx1.fillStyle = 'black';
      for (let x = 0; x * step < data.length; x++) {
        let chunk = data.slice(x * step, (x + 1) * step);
        let min = chunk.reduce((a, b) => Math.min(a, b));
        let max = chunk.reduce((a, b) => Math.max(a, b));
        ctx1.rect(x, scale(max), 1, scale(min) - scale(max) + 1);
        ctx1.fill();
      }
    }
  </script>
</body>

</html>